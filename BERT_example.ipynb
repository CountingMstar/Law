{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 허브에는 45019개의 데이터셋이 있습니다.\n",
      "처음 10개 데이터셋: ['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews']\n"
     ]
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "\n",
    "all_datasets = list_datasets()\n",
    "print(f\"현재 허브에는 {len(all_datasets)}개의 데이터셋이 있습니다.\")\n",
    "print(f\"처음 10개 데이터셋: {all_datasets[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--emotion-a4cde36e64166129\n",
      "Found cached dataset json (/home/moonstar/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-a4cde36e64166129/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023694992065429688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1008231c34246a0837561ac4b973707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# emotion 데이터셋이 다운로드되지 않으면 SetFit/emotion을 사용합니다.\n",
    "emotions = load_dataset(\"SetFit/emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SetFit/emotion 데이터셋의 경우 수동으로 ClassLabel 객체를 만들어 label에 할당합니다.\n",
    "from datasets import ClassLabel\n",
    "\n",
    "emotions['train'].features['label'] = ClassLabel(\n",
    "    num_classes=6, \n",
    "    names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'label_text'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = emotions[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0, 'label_text': 'sadness'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label', 'label_text']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None), 'label_text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy'], 'label': [0, 0, 3, 2, 3], 'label_text': ['sadness', 'sadness', 'anger', 'love', 'anger']}\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy']\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[\"text\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_text\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emotions.set_format(type=\"pandas\")\n",
    "df = emotions[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_text  \\\n",
       "0                            i didnt feel humiliated      0    sadness   \n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love   \n",
       "4                               i am feeling grouchy      3      anger   \n",
       "\n",
       "  label_name  \n",
       "0    sadness  \n",
       "1    sadness  \n",
       "2      anger  \n",
       "3       love  \n",
       "4      anger  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_int2str(row):\n",
    "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
    "\n",
    "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYYklEQVR4nO3debhkVX3u8e9ry4w2owotsVUavCCC0KIYNI444ECUBHw0gnjFIXGIAyFXr1cj3qioETU+StSLoCIRJ66oiANoVIbTStMgYdC0VxsERGlFRBl+949areXxNL3Qc06dU+f7eZ56zt5r71p7rerqemutXVU7VYUkSRtyp1E3QJI0PxgYkqQuBoYkqYuBIUnqYmBIkroYGJKkLgaGNMcl2TXJBUl+keQlf8T9D0/yHzPRNi0sBoZGKsnqJL9KcsPQbcdRt2uOOQr4alXdpareOdUOSR6X5GstVK5NcnaSp8xyOzXmDAzNBU+uqi2HblcOb0xy51E1bI64F3Dx+jYmORj4OHAicE/g7sBrgSfPSuu0YBgYmpOSVJK/TXI5cHkre1Kbmrk+yTeTPGBo/wcm+XZ7h31Kko8lOaZt+4MpmVb/zm15kyRvTfL/klyd5L1JNmvbHpHkR0lekeSaJFclec5QPZsleVuSHyRZm+Q/WtnpSV486ZgXJvnL9fT3KUkubn07K8l/a+VfAR4JvLuNvnaZdL8AbwfeUFXvr6q1VXVbVZ1dVc9bz7GOS/LDJD9PsiLJw4a27Ztkom27OsnbW/mmST6c5LrWxvOT3L1tW5zkA+2xWZPkmCSL2rad22hnbZKfJDllvf/omvMMDM1lBwEPBnZL8kDgg8DzgW2B9wGntRf7jYFPAycB2zB4t/30O3CcNwG7AHsBOwNLGLxDX+cewOJW/lzgX5Ns3ba9FdgHeGg79lHAbcCHgGetqyDJnu3+p08+eAuBk4GXAdsDnwP+b5KNq+pRwNeBv2ujr8sm3X1XYCfg1DvQ3/NbX7cBPgp8PMmmbdtxwHFVdVfgvsC/t/LD2mOwE4PH/wXAr9q2E4BbGDx2DwQOAP572/YG4IvA1gxGP++6A+3UHGNgaC74dHvXen2STw+V/3NV/bSqfgUcCbyvqs6tqlur6kPAr4GHtNtGwDuq6uaqOpXBi+IGtXfoRwJ/3471C+B/A4cO7XYz8E+t7s8BNwC7JrkTcATw0qpa09r1zar6NXAasEuSZa2OvwFOqarfTNGMQ4DTq+rMqrqZQQhtxiCENmTb9veqnv4CVNWHq+q6qrqlqt4GbMIgeNb1deck21XVDVV1zlD5tsDOrZ8rqurnbZTxROBlVfXLqroG+Bd+9/jdzGBKbcequqmqPPk+jxkYmgsOqqqt2u2gofIfDi3fC3jFULBcz+Dd7o7ttqZ+/5c0f9B57O2BzYEVQ/V+oZWvc11V3TK0fiOwJbAdsCnwvcmVVtVNwCnAs1qwPIPBCGgqOw63t6puY9D3JR3tv6793aFjXwCSvDLJJW2a6HoGI4ft2ubnMhht/WebdnpSKz8JOAP4WJIrk7wlyUYM/l02Aq4aevzeB9yt3e8oIMB5bcrtiN52au4xMDSXDQfAD4E3DgXLVlW1eVWdzODd9ZI2Wljnz4aWf8kgFABIco+hbT9hMLWy+1C9i6tqy472/QS4icHUzVQ+BDwTeDRwY1V9az37XcnghXdd+8IgDNd0tOFSBo9N1xRcO19xFPDXwNZVtRWwlsGLOlV1eVU9g8EL/puBU5Ns0UZXr6+q3RiMfJ4EPLsd+9fAdkOP312ravdW34+r6nlVtSOD6cT3rDt3pPnHwNB88W/AC5I8OANbJDkwyV2AbzGYQ39Jko2SPA3Yd+i+K4Hdk+zV5upft25Dezf/b8C/JLkbQJIlSR63oQa1+34QeHuSHZMsSrJfkk3a9m8xOJ/xNtY/uoDBeYIDkzy6vWt/BYMX4W92tKGAlwP/M8lzktw1yZ2S7J/k+CnuchcGj9W1wJ2TvBa467qNSZ6VZPvWt+tb8W1JHplkj3Yy++cMpppuq6qrGJyjeNvQse+b5C9afX+V5J6tnp8xeBNw24b6pbnJwNC8UFUTwPOAdzN44bkCOLxt+w3wtLb+UwbnBD45dN/LgH8CvsTgE1eT59H/odV3TpKft/12pc8rgVUMzpn8lMG78uH/VycCewAfvp2+XcrgBPm7GIxanszgo8ZTne+Y6v6nMujzEQxGK1cDxwCfmWL3MxhMuV3GYBrsJn5/6u/xwMVJbmBwAvzQdg7pHgxOrP8cuAQ4m9+F4LOBjYHvMvi3OZXfTZE9CDi31Xcag/M93+/pl+aeeAEljaMkJwA/qqrXjLgdzwaOrKr9R9kOaTo4wpBmSJLNgRcBU00NSfOOgSHNgHYO5FoG00MfHXFzpGnhlJQkqYsjDElSl7H+Ubftttuuli5dOupmSNK8smLFip9U1faTy8c6MJYuXcrExMSomyFJ80qSKX8pwSkpSVIXA0OS1MXAkCR1MTAkSV0MDElSFwNDktTFwJAkdRnr72GsWrOWpUf/wSWUJWmsrX7TgTNSryMMSVIXA0OS1MXAkCR1MTAkSV0MDElSlzkVGEm+Oeo2SJKmNqcCo6oeOuo2SJKmNqcCI8kNGTg2yUVJViU5pG07MclBQ/t+JMlTR9ZYSVpg5lRgNE8D9gL2BB4DHJtkB+ADwOEASRYDDwX+4Ft5SY5MMpFk4tYb185WmyVp7M3FwNgfOLmqbq2qq4GzgQdV1dnAsiTbA88APlFVt0y+c1UdX1XLq2r5os0Xz27LJWmMzbefBjkReBZwKPCcEbdFkhaUuTjC+DpwSJJFbTTxcOC8tu0E4GUAVfXdkbROkhaouTbCKOBTwH7AyrZ+VFX9GKCqrk5yCfDpkbVQkhaoORMYSbYFflpVBbyq3SbvszmwDDh5lpsnSQvenJiSSrIj8C3grbezz2OAS4B3VZUff5KkWTYnRhhVdSWwywb2+RJwr9lpkSRpsjkxwpAkzX0GhiSpy5yYkpopeyxZzMQMXapQkhYaRxiSpC4GhiSpi4EhSepiYEiSuhgYkqQuBoYkqYuBIUnqYmBIkroYGJKkLgaGJKmLgSFJ6mJgSJK6GBiSpC4GhiSpi4EhSepiYEiSuhgYkqQuY33FvVVr1rL06NNH3QxJY2L1Ar+CpyMMSVIXA0OS1MXAkCR1MTAkSV0MDElSlxkLjCRLk1w0U/VLkmaXIwxJUpcNBkaSLZKcnmRlkouSHJLktUnOb+vHJ0nbd5+230rgb4fqODzJJ5N8IcnlSd4ytO2AJN9K8u0kH0+yZSt/U5LvJrkwyVtb2V+1Y65M8rVpfzQkSevVM8J4PHBlVe1ZVfcHvgC8u6oe1NY3A57U9v0/wIuras8p6tkLOATYAzgkyU5JtgNeAzymqvYGJoCXJ9kW+Etg96p6AHBMq+O1wONa/U+ZqrFJjkwykWTi1hvXdnRPktSjJzBWAY9N8uYkD6uqtcAjk5ybZBXwKGD3JFsBW1XVunf+J02q58tVtbaqbgK+C9wLeAiwG/CNJBcAh7XytcBNwAeSPA24sdXxDeCEJM8DFk3V2Ko6vqqWV9XyRZsv7nkMJEkdNvjTIFV1WZK9gScCxyT5MoPppuVV9cMkrwM27TjWr4eWb23HDnBmVT1j8s5J9gUeDRwM/B3wqKp6QZIHAwcCK5LsU1XXdRxbkvQn6jmHsSNwY1V9GDgW2Ltt+kk733AwQFVdD1yfZP+2/Zkdxz8H+PMkO7djbZFkl1bv4qr6HPD3wJ5t+32r6tyqei1wLbBTZz8lSX+inh8f3AM4NsltwM3AC4GDgIuAHwPnD+37HOCDSQr44oYqrqprkxwOnJxkk1b8GuAXwGeSbMpgFPLytu3YJMta2ZeBlR3tlyRNg1TVqNswYzbZYVntcNg7Rt0MSWNiofxabZIVVbV8crnfw5AkdTEwJEldDAxJUpexvuLeHksWM7FA5hwlaaY5wpAkdTEwJEldDAxJUhcDQ5LUxcCQJHUxMCRJXQwMSVIXA0OS1MXAkCR1MTAkSV0MDElSFwNDktTFwJAkdTEwJEldDAxJUhcDQ5LUxcCQJHUZ6yvurVqzlqVHnz7qZmhEVnu1RWlaOcKQJHUxMCRJXQwMSVIXA0OS1MXAkCR1MTAkSV3mbWBkYN62X5Lmm2l/wU3y6SQrklyc5MhWdkOSNyZZmeScJHdv5fdt66uSHJPkhqF6XpXk/CQXJnl9K1ua5NIkJwIXATtNd/slSVObiXfoR1TVPsBy4CVJtgW2AM6pqj2BrwHPa/seBxxXVXsAP1pXQZIDgGXAvsBewD5JHt42LwPeU1W7V9UPJh88yZFJJpJM3Hrj2hnoniQtTDMRGC9JshI4h8EIYBnwG+CzbfsKYGlb3g/4eFv+6FAdB7Tbd4BvA/dr9QD8oKrOWd/Bq+r4qlpeVcsXbb74T++NJAmY5p8GSfII4DHAflV1Y5KzgE2Bm6uq2m63dhw3wD9X1fsm1b8U+OU0NlmS1Gm6RxiLgZ+1sLgf8JAN7H8O8PS2fOhQ+RnAEUm2BEiyJMndprmtkqQ7YLoD4wvAnZNcAryJQSDcnpcBL09yIbAzsBagqr7IYIrqW0lWAacCd5nmtkqS7oBpnZKqql8DT5hi05ZD+5zKIAAA1gAPqapKciiw69B+xzE4KT7Z/aevxZKkXqP+efN9gHcnCXA9cMRomyNJWp+RBkZVfR3Yc5RtkCT18ZvSkqQuo56SmlF7LFnMhFddk6Rp4QhDktTFwJAkdTEwJEldDAxJUhcDQ5LUxcCQJHUxMCRJXQwMSVIXA0OS1MXAkCR1MTAkSV0MDElSFwNDktTFwJAkdTEwJEldDAxJUhcDQ5LUZayvuLdqzVqWHn36qJuhabDaKydKI+cIQ5LUxcCQJHUxMCRJXQwMSVIXA0OS1GUkgZHkJUkuSfKRURxfknTHjepjtS8CHlNVP/pjK0hy56q6ZRrbJEm6HbM+wkjyXuA+wOeTvDrJB5Ocl+Q7SZ7a9lma5OtJvt1uD23lj2jlpwHfne22S9JCNuuBUVUvAK4EHglsAXylqvZt68cm2QK4BnhsVe0NHAK8c6iKvYGXVtUuU9Wf5MgkE0kmbr1x7Ux2RZIWlFF/0/sA4ClJXtnWNwX+jEGgvDvJXsCtwHA4nFdV/7W+CqvqeOB4gE12WFYz0WhJWohGHRgBnl5Vl/5eYfI64GpgTwajoJuGNv9y1lonSfqtUX+s9gzgxUkCkOSBrXwxcFVV3Qb8DbBoRO2TJDWjDow3ABsBFya5uK0DvAc4LMlK4H44qpCkkRvJlFRVLR1aff4U2y8HHjBU9A+t/CzgrBlsmiRpPUY9wpAkzRMGhiSpi4EhSeoy6o/Vzqg9lixmwiu1SdK0cIQhSepiYEiSuhgYkqQuBoYkqYuBIUnqYmBIkroYGJKkLgaGJKmLgSFJ6mJgSJK6GBiSpC4GhiSpi4EhSepiYEiSuhgYkqQuBoYkqYuBIUnqMtZX3Fu1Zi1Ljz591M2YV1Z7hUJJ6+EIQ5LUxcCQJHUxMCRJXQwMSVIXA0OS1GXWAyPJDbN9TEnSn84RhiSpy8gCIwPHJrkoyaokh7TyjyU5cGi/E5IcnGRR2//8JBcmef6o2i5JC9EoRxhPA/YC9gQeAxybZAfgFOCvAZJsDDwaOB14LrC2qh4EPAh4XpJ7T640yZFJJpJM3Hrj2lnpiCQtBKMMjP2Bk6vq1qq6GjibQRB8Hnhkkk2AJwBfq6pfAQcAz05yAXAusC2wbHKlVXV8VS2vquWLNl88S12RpPE3534apKpuSnIW8DjgEOBjbVOAF1fVGaNqmyQtZKMcYXwdOKSdm9geeDhwXtt2CvAc4GHAF1rZGcALk2wEkGSXJFvMcpslacEa5QjjU8B+wEqggKOq6sdt2xeBk4DPVNVvWtn7gaXAt5MEuBY4aDYbLEkL2awHRlVt2f4W8Kp2m7zPzcA2k8puA/5Hu0mSZpnfw5AkdTEwJEldDAxJUhcDQ5LUZc59D2M67bFkMRNeclSSpoUjDElSFwNDktTFwJAkdTEwJEldDAxJUhcDQ5LUxcCQJHUxMCRJXQwMSVIXA0OS1MXAkCR1MTAkSV0MDElSFwNDktTFwJAkdTEwJEldDAxJUpexvuLeqjVrWXr06aNuBqu96p+kMeAIQ5LUxcCQJHUxMCRJXQwMSVIXA0OS1GXOBEaSzyXZatTtkCRNbcY+VpvkzlV1S8d+AVJVT5yptkiS/nQbHGEk2SLJ6UlWJrkoySFJVifZrm1fnuSstvy6JCcl+QZwUpLDk3wmyVlJLk/yv9p+S5NcmuRE4CJgp3V1TnW8dp99kpydZEWSM5LsMFMPiiTpD/WMMB4PXFlVBwIkWQy8+Xb23w3Yv6p+leRwYF/g/sCNwPlJTgd+AiwDDquqc1q96z1eko2AdwFPraprW4i8EThi8sGTHAkcCbDortt3dE+S1KPnHMYq4LFJ3pzkYVW1dgP7n1ZVvxpaP7OqrmtlnwT2b+U/WBcWHcfblUHonJnkAuA1wD2nOnhVHV9Vy6tq+aLNF3d0T5LUY4MjjKq6LMnewBOBY5J8GbiF34XNppPu8svJVaxnffJ+t3e8TwEXV9V+G2qvJGlm9JzD2BG4sao+DBwL7A2sBvZpuzx9A1U8Nsk2STYDDgK+8Ucc71Jg+yT7tX02SrL7htouSZo+Pecw9gCOTXIbcDPwQmAz4ANJ3gCctYH7nwd8gsEU0oeraiLJ0jtyvKr6TZKDgXe2cyh3Bt4BXNzRfknSNOiZkjoDOGOKTbtMse/rptjvR1V10KT9VjM4JzFctrQtTnm8qroAePiG2itJmhlz5ot7kqS5bUavh1FVJwAnzOQxJEmzwxGGJKnLWF9xb48li5nwaneSNC0cYUiSuhgYkqQuBoYkqYuBIUnqYmBIkroYGJKkLgaGJKmLgSFJ6pKqyZerGB9JfsHgp9EXgu0YXMlwoVhI/V1IfYWF1d+52td7VdUfXLJ0rL/pDVxaVctH3YjZkGRiofQVFlZ/F1JfYWH1d7711SkpSVIXA0OS1GXcA+P4UTdgFi2kvsLC6u9C6issrP7Oq76O9UlvSdL0GfcRhiRpmhgYkqQuYxkYSR6f5NIkVyQ5etTt+WMl+WCSa5JcNFS2TZIzk1ze/m7dypPkna3PFybZe+g+h7X9L09y2Cj6siFJdkry1STfTXJxkpe28nHt76ZJzkuysvX39a383knObf06JcnGrXyTtn5F2750qK5/bOWXJnnciLq0QUkWJflOks+29XHu6+okq5JckGSilc3/53JVjdUNWAR8D7gPsDGwEtht1O36I/vycGBv4KKhsrcAR7flo4E3t+UnAp8HAjwEOLeVbwN8v/3dui1vPeq+TdHXHYC92/JdgMuA3ca4vwG2bMsbAee2fvw7cGgrfy/wwrb8IuC9bflQ4JS2vFt7jm8C3Ls99xeNun/r6fPLgY8Cn23r49zX1cB2k8rm/XN5HEcY+wJXVNX3q+o3wMeAp464TX+Uqvoa8NNJxU8FPtSWPwQcNFR+Yg2cA2yVZAfgccCZVfXTqvoZcCbw+Blv/B1UVVdV1bfb8i+AS4AljG9/q6puaKsbtVsBjwJObeWT+7vucTgVeHSStPKPVdWvq+q/gCsY/B+YU5LcEzgQeH9bD2Pa19sx75/L4xgYS4AfDq3/qJWNi7tX1VVt+cfA3dvy+vo97x6PNgXxQAbvuse2v22K5gLgGgYvBt8Drq+qW9ouw23/bb/a9rXAtsyf/r4DOAq4ra1vy/j2FQbh/8UkK5Ic2crm/XN53H8aZKxVVSUZq89FJ9kS+ATwsqr6+eCN5cC49beqbgX2SrIV8CngfqNt0cxI8iTgmqpakeQRI27ObNm/qtYkuRtwZpL/HN44X5/L4zjCWAPsNLR+z1Y2Lq5uw1Xa32ta+fr6PW8ejyQbMQiLj1TVJ1vx2PZ3naq6HvgqsB+D6Yh1b+SG2/7bfrXti4HrmB/9/XPgKUlWM5gifhRwHOPZVwCqak37ew2DNwP7MgbP5XEMjPOBZe0TGBszOGl22ojbNJ1OA9Z9WuIw4DND5c9un7h4CLC2DX/PAA5IsnX7VMYBrWxOaXPUHwAuqaq3D20a1/5u30YWJNkMeCyD8zZfBQ5uu03u77rH4WDgKzU4M3oacGj7ZNG9gWXAebPSiU5V9Y9Vdc+qWsrg/+NXquqZjGFfAZJskeQu65YZPAcvYhyey6M84z5TNwafOriMwZzwq0fdnj+hHycDVwE3M5i/fC6DudwvA5cDXwK2afsG+NfW51XA8qF6jmBwgvAK4Dmj7td6+ro/g3nfC4EL2u2JY9zfBwDfaf29CHhtK78PgxfBK4CPA5u08k3b+hVt+32G6np1exwuBZ4w6r5toN+P4HefkhrLvrZ+rWy3i9e9Bo3Dc9mfBpEkdRnHKSlJ0gwwMCRJXQwMSVIXA0OS1MXAkCR1MTAkSV0MDElSl/8Peqi5tVZ4GGAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEHCAYAAABP3uaxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWhUlEQVR4nO3de7RkZX3m8e8TQEFwwJYjgyC2CURHjdeOQrwhXifqQEaiEi+YsOyY0STGJGqi42V5v6zoZGVmRRQXCCoabxCDImGkURGwW0VAYiQKCiK0CiIRVOA3f+z3DEWnu8/pU1Xn9n4/a5119t61a+/fW5en3np31a5UFZKk1e1XlroASdL0GfaS1AHDXpI6YNhLUgcMe0nqgGEvSR0w7LUqJHltkpOWug5puTLsNRVJ/irJp7dY9q1tLHvW4lZ3u/1fluTGJDckuTrJ8Un2mMB2bxj5u3VkHzckefYkat/Ovi9L8vhp7kMrj2GvaTkb+K0kOwEk2RfYBXjwFssObOvOW5KdJ1zr06pqD+AhwDrgVTtYT5Lc7rlUVXvM/gHfnd1H+/vAxCqX5smw17R8mSHcH9TmHwV8DvjmFsv+raq+n+TuSU5N8uMklyZ5weyG2hDNR5OclOR64PlJ7pVkQ5KfJjkD2Htk/V3buj9Kcl2SLyfZZ66Cq+pK4NPA/dt2Dk5yTtvGBUkOHdnHWUnemOSLwM+AX51r+62uG5Ps3eZfmeTmJP+pzb8+ybva9B2TvCPJd9s7jr9PstvItp6a5GuttnOSPKAtPxE4APjH9i7iZXPVpT4Y9pqKqvoFcB7w6Lbo0cDngS9ssWy2V38ycAVwd+BI4E1JDhvZ5OHAR4G9gA8AHwQ2MYT864GjR9Y9GtgTuAdwV+CFwI1z1ZzkHsBvA19Nsh/wT8AbgDXAXwAfSzIzcpXnAuuBOwOXz7X9qrqJ4UXwMW3RY9r1HjEyv6FNvwX4dYYXxgOB/YBXtzofDLwP+MPWvncDpya5Y1U9l9u/k3jbXHWpD4a9pmkDtwX7oxjC/vNbLNvQQvYRwMur6qaq+hrwXuB5I9v6UlV9sqpuBWaA3wT+Z1X9vKrOBv5xZN1fMoTggVV1S1Vtqqrrt1PnJ5Ncx/BCtAF4E/Ac4LSqOq2qbq2qM4CNDC8Gs46vqour6uaq+uUO3CaPaUNRDwD+ts3v2tp0dpIwvIj8WVX9uKp+2mqaPbaxHnh3VZ3X2ncC8HPg4HnWoA4Z9pqms4FHJlkDzFTVt4BzGMby1zAMl5zN0JufDbVZlzP0Zmd9b2T67sC1VfXvW6w/60TgdODkJN9P8rYku2ynziOqaq+qumdV/Y+quhG4J/C7bZjkuvZi8Ehg323UNF8bgEMZjg9cCJzB0KM/GLi0qn7E8GJ2J2DTyL4/05bTavvzLWq7B8PtIm3VpA90SaO+xDCc8gLgiwBVdX2S77dl36+q7yS5GViT5M4jgX8AcOXItkZPz3oVcJcku48E/gGz67Re9uuA1yVZC5zGcKzguB2o/XvAiVX1gu2ss5BTxp4D3Bv4HWBDVX0jyQEM7xhmh3B+yDDsdL92HGFrtb2xqt44wbq0ytmz19S0HvJG4KUMwzezvtCWnd3W+x5DCL65HcR8AHAMsNXPzVfV5W27r0tyhySPBJ42e3mSxyb5jfapn+sZhnVu3cHyTwKeluRJSXZqdR2aZP8d3M6Wtf+M4VjDi7gt3M9hOK6woa1zK/Ae4J1J7tbatF+SJ7X13wO8MMnD2yeBdk/ylCR3bpdfzTwOGKsvhr2mbQNwN4aAn/X5tmz0I5dHAWuB7wOfAF5TVf+8ne3+HvBw4MfAa4D3j1z2nxkO5l4PXNJqOHFHim4vQIcDfw1sZuhN/yWTec5sYPik0vkj83fm9rfHy4FLgXPbJ5D+meEdAVW1keGd0d8B17b1nj9y3TcDr2pDPH8xgXq1CsQfL5Gk1c+evSR1wLCXpA4Y9pLUAcNekjpg2EtSBxb1S1V77713rV27djF3KUnd2LRp0w+ramZrly1q2K9du5aNGzcu5i4lqRtJtnlCPodxJKkDhr0kdcCwl6QOGPaS1IF5HaBNchnwU+AW4OaqWtfOR/5hhpNXXQY8o6qunU6ZkqRx7EjP/rFV9aCqWtfmXwGcWVUHAWe2eUnSMjTOMM7hwAlt+gTgiLGrkSRNxXzDvoDPJtmUZH1btk9VXdWmfwDsM/HqJEkTMd8vVT2yqq5sv5pzRpJ/Gb2wqirJVk+M314c1gMccMABYxW7je2PdX3P5y+pB/Pq2c/+DmZVXcPwK0IPA65Osi9A+3/NNq57bFWtq6p1MzNb/RbvWKpqu39zrSNJPZgz7NvvW955dhp4InARcCpwdFvtaOCUaRUpSRrPfIZx9gE+0YZLdgY+WFWfSfJl4CNJjgEuB54xvTIlSeOYM+yr6tvAA7ey/EfA46ZRlLSaeZxJS2FRz3opafthncQw11R4ugRJ6oBhL0kdcBhHy8o449kOf0jbZthrWXE8W5oOh3EkqQOGvSR1wGGcFcKxbGn5WUnfmTDsVwjHsqXlZ67n3XJ6bjqMI0kdMOwlqQOGvSR1wLCXpA4Y9pLUAcNekjrgRy8lTYXfDVleDHtJU+F3Q5YXh3EkqQOGvSR1wLCXpA4Y9pLUAcNekjpg2EtSBwx7SeqAYS9JHTDsJakDhr0kdcCwl6QOGPaS1AHDXpI6YNhLUgcMe0nqwLzDPslOSb6a5FNt/l5JzktyaZIPJ7nD9MqUJI1jR3r2fwpcMjL/VuCdVXUgcC1wzCQLkyRNzrzCPsn+wFOA97b5AIcBH22rnAAcMYX6JEkTMN+e/buAlwG3tvm7AtdV1c1t/gpgv8mWJkmalDnDPslTgWuqatNCdpBkfZKNSTZu3rx5IZuQJI1pPj37RwD/LcllwMkMwzf/C9gryewPlu8PXLm1K1fVsVW1rqrWzczMTKBkSdKOmjPsq+qvqmr/qloLPAv4v1X1bOBzwJFttaOBU6ZWpSRpLON8zv7lwEuTXMowhn/cZEqSJE3aznOvcpuqOgs4q01/G3jY5EuSJE2a36CVpA4Y9pLUAcNekjpg2EtSBwx7SeqAYS9JHTDsJakDhr0kdcCwl6QOGPaS1AHDXpI6YNhLUgcMe0nqgGEvSR0w7CWpA4a9JHXAsJekDhj2ktQBw16SOmDYS1IHDHtJ6oBhL0kdMOwlqQOGvSR1wLCXpA4Y9pLUAcNekjpg2EtSBwx7SeqAYS9JHTDsJakDhr0kdWDOsE+ya5Lzk1yQ5OIkr2vL75XkvCSXJvlwkjtMv1xJ0kLMp2f/c+Cwqnog8CDgyUkOBt4KvLOqDgSuBY6ZWpWSpLHMGfY1uKHN7tL+CjgM+GhbfgJwxDQKlCSNb15j9kl2SvI14BrgDODfgOuq6ua2yhXAftu47vokG5Ns3Lx58wRKliTtqHmFfVXdUlUPAvYHHgbcZ747qKpjq2pdVa2bmZlZWJWSpLHs0Kdxquo64HPAIcBeSXZuF+0PXDnZ0iRJkzKfT+PMJNmrTe8GPAG4hCH0j2yrHQ2cMqUaJUlj2nnuVdgXOCHJTgwvDh+pqk8l+QZwcpI3AF8FjptinZKkMcwZ9lX1deDBW1n+bYbxe0nSMuc3aCWpA4a9JHXAsJekDhj2ktQBw16SOmDYS1IHDHtJ6oBhL03BmjVrSLLDf8CCrpeENWvWLHGrtZzN5xu0knbQtddeS1Ut6j5nXyykrbFnL0kdMOwlqQMrIuwXOv45zhio45/T4X2plWa1PGZXxJi945+rh/elVprV8phdET17SdJ4DHtJ6oBhv4z42WxJ07Iixux7sVrGBiUtP/bsJakDhr0kdcCwl7Rgi32cyWNMC+eYvaQFW+zjTB5jWjh79pLUAcNekjpg2EtSBwx7SeqAYS9JHTDsJakDhr0kdcCwl6QOGPaS1AHDXpI6YNhLUgfmDPsk90jyuSTfSHJxkj9ty9ckOSPJt9r/u0y/XEnSQsynZ38z8OdVdV/gYOBFSe4LvAI4s6oOAs5s85KkZWjOsK+qq6rqK236p8AlwH7A4cAJbbUTgCOmVKMkaUw7NGafZC3wYOA8YJ+quqpd9ANgn21cZ32SjUk2bt68eZxaJUkLNO+wT7IH8DHgJVV1/ehlNZzQeqsnta6qY6tqXVWtm5mZGatYSdLCzCvsk+zCEPQfqKqPt8VXJ9m3Xb4vcM10SpQkjWs+n8YJcBxwSVX9zchFpwJHt+mjgVMmX54kaRLm87OEjwCeC1yY5Gtt2V8DbwE+kuQY4HLgGVOpUFqh/Ak9LSdzhn1VfQHY1qP2cZMtR1o9FvO3WcEXF22f36CVpA4Y9pLUAcNekjownwO00kQ5tqyVZjU8Zg17LToPXGqlWQ2PWYdxJKkDhr0kdWDFDOP08la8l3ZKWlwrJuxXw5jZfPTSTkmLy2EcSeqAYS9JHVgxwziSlieHAlcGw17SWBbzOJMvLAvnMI4kdcCwl6QOGPaS1AHDXpI6YNhLUgcMe0nqgGEvSR0w7CWpA4a9JHXAsJekDhj2ktQBw16SOmDYS1IHDHtJ6oCnOJamZLFPx3uXu9xlUffXk9VwXxr20hQs9BzvSRb9d4i1fePcH8vp/nQYR5I6YNhLUgccxtGiWw3jn9JKM2fYJ3kf8FTgmqq6f1u2BvgwsBa4DHhGVV07vTK1WqyW8U9ppZnPMM7xwJO3WPYK4MyqOgg4s81LkpapOcO+qs4GfrzF4sOBE9r0CcARky1LkjRJCx2z36eqrmrTPwD22daKSdYD6wEOOOCABe6un3HeXtqp1WMxH7M+Xhdu7AO0VVVJtjmQWlXHAscCrFu3bkEDrr2M8/rZbK00PmZXjoV+9PLqJPsCtP/XTK4kSdKkLTTsTwWObtNHA6dMphxJ0jTMGfZJPgR8Cbh3kiuSHAO8BXhCkm8Bj2/zkqRlas4x+6o6ahsXPW7CtUiSpsTTJUhSBwx7SeqAYS9JHTDsJakDhr0kdcCwl6QOGPaS1AHDXpI6YNhLUgcMe0nqgGEvSR0w7CWpA4a9JHXAsJekDhj2ktQBw16SOmDYS1IHDHtJ6oBhL0kdMOwlqQOGvSR1wLCXpA4Y9pLUgZ2XugCpN0nGuryqJlmOxjDXfTXXOot5Xxr20iIzrFePlXRfOowjSR0w7CWpAyt+GGcljZmNY5xx3pXSRuinnT3wvlxeVnzY9/KgsJ1aabwvlxeHcSSpA4a9JHXAsJekDowV9kmenOSbSS5N8opJFSVJmqwFh32SnYD/DfxX4L7AUUnuO6nCJEmTM07P/mHApVX17ar6BXAycPhkypIkTdI4Yb8f8L2R+SvasttJsj7JxiQbN2/ePMbuJEkLNfUDtFV1bFWtq6p1MzMz096dJGkrxvlS1ZXAPUbm92/LtmnTpk0/THL5GPtciL2BHy7yPhdbD22EPtrZQxvBdk7LPbd1QRb6LbckOwP/CjyOIeS/DPxeVV28oA1OSZKNVbVuqeuYph7aCH20s4c2gu1cCgvu2VfVzUleDJwO7AS8b7kFvSRpMNa5carqNOC0CdUiSZqSHr5Be+xSF7AIemgj9NHOHtoItnPRLXjMXpK0cvTQs5ek7hn2y1ySP0lySZIPLHUtiyXJOUtdwzQkuWGpa1hsSdYmuWip61hukpyWZK9F3afDOP9Rhp/QSVXdugxq+Rfg8VV1xRjb2Lmqbp5gWVqAJDdU1R5LXcdiSrIW+FRV3X+pa5mm+T7HljJbVlTPPsknk2xKcnGS9W3ZDUnemOSCJOcm2act/7U2f2GSN4z2qpL8ZZIvJ/l6kte1ZWvbGTzfD1zE7b8wtiSS/D3wq8Cnk7wyyfuSnJ/kq0kOb+usTfL5JF9pf7/Vlh/alp8KfGMJm7HD2n2aJG9PclG7D5/ZLnt/kiNG1v3A7G2xUmynbScnecrIescnOTLJTm392cfsHy5Bzbsn+af2PLsoyTOTvLrVdFGSY1uQkeShbb0LgBeNbOP5ST6e5DNJvpXkbSOXPTHJl9pj+B+S7NGWvyXJN1q739GW/W7b5wVJzl6Edl6WZO92+bokZ7Xp1yY5MckXgRNb+05JclZr32vaev8hW2a3ubX9jdyGGzLk3elJ9h27cVW1Yv6ANe3/bu1GuytQwNPa8rcBr2rTnwKOatMvBG5o009kOEIehhe7TwGPBtYCtwIHL3U7t2jzZQzfwnsT8Jy2bC+GL7TtDtwJ2LUtPwjY2KYPBf4duNdSt2EBbb4BeDpwBsN3OPYBvgvsCzwG+GRbb0/gO8DOS13zfNvV/m+rbb8DnNDWuQPDuad2A9aPPK7vCGxc7Pu11fyekfk9Z5+Pbf7Ekefh14FHt+m3Axe16ecD327X3RW4nKFTtTdwNrB7W+/lwKvb8/ub3DYCsVf7fyGw3+iyKbfzMmDvNr8OOKtNvxbYBOw20r6rWt2zGbVua9ky8rze2v52Ac4BZtqyZzJ8j2mstq2onj3wJ623cC7Dg+Qg4BcMgQ3DDb+2TR8C/EOb/uDINp7Y/r4KfAW4T9sOwOVVde60ih/TE4FXJPkacBbDk+UAhgfGe5JcyNDe0dNMn19V31nkOiflkcCHquqWqroa2AD8ZlVtAA5KMgMcBXysVt4Q1VbbBnwaeGySOzKcOvzsqrqR4b5/Xrvvz2MIk4O2uuXpuRB4QpK3JnlUVf2k1Xpee+wdBtwvwzj0XlU12+M+cYvtnFlVP6mqmxjecd4TOJjhcfvF1saj2/KfADcBxyX578DP2ja+CByf5AUML5jTbuf2nNruo1lnVNWP2rKPM9zXsO1s2dr+7g3cHzij3R6vYjgdzVhWzA+OJzkUeDxwSFX9rL2V2hX4ZbWXP+AW5m5TgDdX1bu32P5ahp7wchXg6VX1zdstTF4LXA08kOGdyk0jFy/n9ozj/cBzgGcBv7/EtUxMVd3UHtdPYujNndwuCvDHVXX6Etb2r0keAvw28IYkZzIM0ayrqu+1x+Gu89jUz0emZ5+vYQjJo7ZcOcnDGE7JciTwYuCwqnphkocDTwE2JXloVf1ojOb9f9to583cNuS9ZRu3fI5teRC0trHe9vb3CeDiqjpkgc3YqpXUs98TuLYF/X0YegPbcy7DWyQYQmHW6cAfjIwJ7pfkbhOvdvJOB/54ZFz0wW35nsBVNRzweS6T7+kslc8Dz2zj1TMMQ23nt8uOB14CUFUr6nhEs722fZjhBexRwGfastOBP0qyC0CSX0+y+2IWnOTuwM+q6iSGoZmHtIt+2J5LRwJU1XXAdUlme7TPnsfmzwUekeTAtq/dWxv3APas4Zv6f8bQoSHJr1XVeVX1amAzEzy+to12XgY8tK3y9G1cddYTkqxJshtwBMO7kB3d3zeBmSSHtHV2SXK/hbXoNiumZ8/wwH9hkksYboy5hlteApyU5JXtuj8BqKrPJvkvwJdabt7A0Eu8ZUp1T8rrgXcBX0/yKwxj1U8F/g/wsSTPY2jnaujNF0Pv5hDggjb/sqr6AUBVXd0eB59csgrHs822AZ9lGPo4pYYfBQJ4L8Pw5Ffai/1mhiBZTL8BvD3JrcAvgT9qNVwE/IDhRIizfh94X5JiaM92VdXmJM8HPtSGsGAYuvgpcEqSXRl6/y9tl709yUFt2ZkMt+OkbK2duzEMJb2eYQh1e84HPsYw7HJSVW1sowbz3l9V/SLJkcDfJtmTIaffBYx17rFV+9HLJHcCbqyqSvIshoO1K+pTGz1KclfgK1W17VO1DvfthcBD5jGmKi2K9oK1rqpevNS1bM1K6tnvqIcCf9d6QtcBf7C05Wgu7S3tWcA7trPO44HjgHca9NL8rdqevSTpNivpAK0kaYEMe0nqgGEvSR0w7CWpA4a9JHXAsJekDvw/Nv+6XWHkM6oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
    "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False,\n",
    "           color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 16:25:57.264735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 16:25:58.043390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:/home/moonstar/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-06-26 16:25:58.043479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:/home/moonstar/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-06-26 16:25:58.043488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 19204, 6026, 3793, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 부분단어 토큰화 \n",
    "text = \"Tokenizing text is a core task of NLP.\"\n",
    "\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'token', '##izing', 'text', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] tokenizing text is a core task of nlp. [SEP]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 토큰화하기\n",
    "def tokenize(batch):\n",
    "    # return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "    tmp = [batch['text'][i] for i in range(len(batch['text']))]\n",
    "\n",
    "    return tokenizer(tmp, padding=True, truncation=True)\n",
    "\n",
    "# a = emotions[\"train\"][:2]\n",
    "# print(tokenize(a))\n",
    "\n",
    "\n",
    "print(tokenize(emotions[\"train\"][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Special Token</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>[UNK]</td>\n",
       "      <td>[CLS]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Special Token ID</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0      1      2      3       4\n",
       "Special Token     [PAD]  [UNK]  [CLS]  [SEP]  [MASK]\n",
       "Special Token ID      0    100    101    102     103"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n",
    "data = sorted(tokens2ids, key=lambda x : x[-1])\n",
    "df = pd.DataFrame(data, columns=[\"Special Token\", \"Special Token ID\"])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/moonstar/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-a4cde36e64166129/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-c327e532a67b56fc.arrow\n",
      "Loading cached processed dataset at /home/moonstar/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-a4cde36e64166129/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-593c0c7181dfec20.arrow\n",
      "Loading cached processed dataset at /home/moonstar/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-a4cde36e64166129/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-67faaac99ed88b90.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'label_text', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(emotions_encoded[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련(약식)\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서 크기: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "text = \"this is a test\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"입력 텐서 크기: {inputs['input_ids'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n",
      "         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n",
      "         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n",
      "         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n",
      "         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n",
      "         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]],\n",
      "       device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outputs.last_hidden_state[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # 모델 입력을 GPU로 옮깁니다.\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() \n",
    "              if k in tokenizer.model_input_names}\n",
    "    # 마지막 은닉 상태를 추출합니다.\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # [CLS] 토큰에 대한 벡터를 반환합니다.\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_encoded.set_format(\"torch\", \n",
    "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014960765838623047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 16,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666cde83e4d44279977ae9fc74461ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014355182647705078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252a1bc097ab4057814d3f152a9e6a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014881134033203125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5b18384e944e1a9b9372729cfce3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label', 'label_text', 'input_ids', 'attention_mask', 'hidden_state']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_hidden[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 768), (2000, 768))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
    "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
    "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
    "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1013699/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1444544591.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1013699/1444544591.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'module'</span> object is not callable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1013699/\u001b[0m\u001b[1;33m1444544591.py\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1013699/1444544591.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'module'\u001b[0m object is not callable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 특성 스케일을 [0,1] 범위로 조정합니다.\n",
    "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "# UMAP 객체를 생성하고 훈련시킵니다.\n",
    "mapper = umap(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
    "# 2D 임베딩의 데이터프레임을 만듭니다.\n",
    "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
    "df_emb[\"label\"] = y_train\n",
    "df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머 미세튜닝\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 6\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ee5c1a7d9c408aa2ba1c1c32a719b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True, \n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/huggingface_hub/repository.py:729: FutureWarning: Creating a repository through 'clone_from' is deprecated and will be removed in v0.12. Please create the repository first using `create_repo(..., exists_ok=True)`.\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/CountingMstar/distilbert-base-uncased-finetuned-emotion into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotions_encoded[\"train\"],\n",
    "                  eval_dataset=emotions_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d043f4dea073442cd267471bf30c46004563c9415419567b38c826b8ca735d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
